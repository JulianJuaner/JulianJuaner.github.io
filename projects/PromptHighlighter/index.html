<!DOCTYPE html>
<html>

<head>

  <title>Prompt Highlighter</title>
  <link href="https://fonts.googleapis.com/css?family=Noto Serif" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <!-- <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/highlighter_favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <!-- <script src="./static/js/bulma-slider.min.js"></script> -->
  <script src="./static/js/index.js"></script>
  <script type="text/javascript">
    var selectedImage = null;

    function showOutput(image, id) {
      // Remove the selected class from the previously selected image, if any
      if (selectedImage) {
        selectedImage.classList.remove("selected");
      }

      // Add the selected class to the clicked image
      image.classList.add("selected");
      selectedImage = image;

      // Get the model output div
      var outputDiv = document.getElementById(id);

      // Clear the current output
      outputDiv.innerHTML = "";

      // Get the model output for the selected image
      var modelOutput = image.getAttribute("content");

      // Display the model output
      outputDiv.innerHTML = modelOutput;
    }
  </script>
  <script type="text/javascript">
    var selectedImage2 = null;

    function showOutput2(image, id) {
      // Remove the selected class from the previously selected image, if any
      if (selectedImage2) {
        selectedImage2.classList.remove("selected");
      }

      // Add the selected class to the clicked image
      image.classList.add("selected");
      selectedImage2 = image;

      // Get the model output div
      var outputDiv = document.getElementById(id);

      // Clear the current output
      outputDiv.innerHTML = "";

      // Get the model output for the selected image
      var modelOutput = image.getAttribute("content");

      // Display the model output
      outputDiv.innerHTML = modelOutput;
    }
  </script>
</head>

<body onload="showOutput(document.querySelector('#image-selection1 img'), 'model-output1'); showOutput2(document.querySelector('#image-selection2 img'), 'model-output2')">

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title"> <img src="./static/images/highlighter_favicon.png"
                style="width:4%;" />
              Prompt Highlighter: Interactive Control for <br /> Multi-Modal LLMs
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://julianjuaner.github.io/" target="_blank">Yuechen Zhang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://thesouthfrog.com/about.me/" target="_blank">Shengju Qian</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com.hk/citations?user=9xcCm1oAAAAJ&hl=en" target="_blank">Bohao
                  Peng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="http://shuliu.me/" target="_blank">Shu Liu</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://jiaya.me/" target="_blank">Jiaya Jia</a><sup>1,2</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>The Chinese University of Hong Kong,</span>
              <span class="author-block"><sup>2</sup>SmartMore</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2305.18729.pdf" class="button is-normal is-rounded is-dark"
                    target="_blank">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Arxiv Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2305.18729" class="external-link button is-normal is-rounded is-dark"
                    target="_blank">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/dvlab-research/Prompt-Highlighter/"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
        <!-- <img src="./static/images/logo.png" style="width:100%;"/> -->
      </div>
    </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <section class="hero is-light is-small">
        <div class="hero-body">
          <span style="background-color: rgb(249, 246, 217);"><b> Control text generation by highlighting our prompt!
            </b></span>Prompt Highlighter is a training-free inference pipeline, which facilitates token-level user
          interactions for customized generation. Our method is compatible for both LLMs and VLMs.</b>
          <div class="container" style="text-align:center">
            <br>
            <div class="video-container">
              <video id="myVideo" autoplay muted controls>
                <source src="./static/images/demo_vid.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <script>
                window.onload = function () {
                  var vid = document.getElementById("myVideo");
                  vid.currentTime = 2;
                };
              </script>
              This example is based on the original LLaVA-v1.5 13B, without any training.
            </div>
          </div>
        </div>
      </section>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p style="font-size: small;">
              This study targets a critical aspect of multi-modal LLMs' (LLMs&VLMs) inference: <span
                style="background-color: rgb(249, 246, 217);">explicit controllable text generation</span>. Multi-modal
              LLMs empower multi-modality understanding with the capability of semantic generation yet bring less
              explainability and heavier reliance on prompt contents due to their autoregressive generative nature.
              <span style="background-color: rgb(249, 246, 217);">While manipulating prompt formats could improve
                outputs, designing specific and precise prompts per task can be challenging and ineffective. To tackle
                this issue, we introduce a novel inference method, Prompt Highlighter, which enables users to highlight
                specific prompt spans to interactively control the focus during generation.</span>
              Motivated by the classifier-free diffusion guidance, we form regular and unconditional context pairs based
              on highlighted tokens, demonstrating that the autoregressive generation in models can be guided in a
              classifier-free way. Notably, we find that, during inference, guiding the models with highlighted tokens
              through the attention weights leads to more desired outputs. Our approach is compatible with current LLMs
              and VLMs, achieving impressive customized generation results without training. Experiments confirm its
              effectiveness in focusing on input contexts and generating reliable content. <span
                style="background-color: rgb(249, 246, 217);">Without tuning on LLaVA-v1.5, our method secured 69.5 in
                the MMBench test and 1552.5 in MME-perception.</span>
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
      <section class="hero teaser">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-justified">
            <div class="column is-four-fifths">
              <br>
              <img src="./static/images/pipeline.png" width="100%" />
              <br />
              <p style="font-size: small;">
                An abstract pipeline of Prompt Highlighter. Users can control the focus of generation by marking out
                specific image regions or text spans. Then a token-level mask <b>m</b> is created to guide the language
                model's inference.
              </p>
            </div>
          </div>
        </div>
      </section>

      <!-- Extensions. -->
      <br>
      <br>
      <h2 class="title is-5">Application 1: Partial Context Highlighter</h2>
      Click image to get customized text generation results.
      <section class="hero is-light is-small">
        <div class="hero-body">
          <div class="container" style='text-align:center'>

            <!-- Image selection -->
              <div id="image-selection1" class="item item-exp1">
                <!-- Add your images here -->
                <img src="./static/images/cr7_nomask.png" onclick="showOutput(this, 'model-output1')" content="VANILLA INFERENCE: The image features a man wearing a red and green soccer jersey, standing on a field and smiling. He appears to be a soccer player, possibly a professional athlete, as he is wearing a uniform and a wristband. The man is the main focus of the scene, and he is surrounded by several other people in the background, some of whom are also wearing uniforms. The atmosphere seems to be lively and energetic, likely related to a soccer game or practice session.
                " />
                <img src="./static/images/cr7_mask_head.png" onclick="showOutput(this, 'model-output1')"
                  content="HIGHLIGHT THE PLAYER'S FACE: <span style='background-color: rgb(249, 246, 217);'>Ronaldo, a smiling soccer player, is the main focus of the image.</span> He is wearing a red and green jersey and is happily posing for the camera. <span style='background-color: rgb(249, 246, 217);'>The smile on his face is contagious, and he appears to be enjoying the moment.</span>
                In the background, there are several other people present, but they are not the main focus of the image. The primary focus remains on the happy soccer player, who is the center of attention in this scene." />
                <img src="./static/images/cr7_mask_jersey.png" onclick="showOutput(this, 'model-output1')" content="HIGHLIGHT THE PLAYER'S JERSEY: The image features <span style='background-color: rgb(249, 246, 217);'>a soccer player wearing a red, green, and yellow jersey with the number seven on it</span>. The player is smiling and appears to be enjoying the game. <span style='background-color: rgb(249, 246, 217);'>He is wearing green and red stripes on his jersey, which are a part of his uniform.</span> The player is standing on a field, possibly during a match or practice session.
                In the background, there are several other people present, possibly teammates or opponents, but they are not the main focus of the image. The main focus is on the soccer player in the red, green, and yellow uniform.
                " />
                <p style="text-align: center">User: Describe this image.</p>
                <!-- Model output -->
                <div id="model-output1">
                  <!-- The model output will be displayed here -->
                </div>
              </div>
          </div>
          <br><br>
            <div class="container" style="text-align:center">
              <div id="image-selection2">
                <!-- Add your images here -->
                <img src="./static/images/titanic_1.png" onclick="showOutput2(this, 'model-output2')" content="VANILLA INFERENCE: As the sun sets over the ocean, the couple on the deck of the ship is lost in each other's embrace. The man, with his arm around the woman, leans in to whisper sweet nothings in her ear. The woman, with her head resting on his chest, listens intently, feeling the warmth and love emanating from him.<br><br>Man: &quotI can't believe we're on this grand ship, sailing across the vast ocean. It's like we're in a fairy tale.&quot<br><br>Woman: &quotIt's truly magical. I feel so close to you right now, like nothing else matters in the world.&quot<br><br>Man: &quotI feel the same way. I'm so grateful to have you by my side on this journey. I promise to always cherish and protect you.&quot<br><br>Woman: &quotI know you will. I love you more than words can express.&quot<br><br>As they continue to embrace, the couple is filled with a sense of contentment and happiness, knowing that they have found a love that transcends time and space." />
                <img src="./static/images/titanic_2.png" onclick="showOutput2(this, 'model-output2')"
                  content="HIGHLIGHT THE COUPLE: As the sun sets over the ocean, <span style='background-color: rgb(249, 246, 217);'>the couple, Jack and Rose, stand on the deck of the Titanic, holding each other close</span>. Jack looks into Rose's eyes and says, <br><br>&quot Rose, I promise you that I will always be here for you, no matter what happens. We'll face any challenges together, and our love will be the strongest force that keeps us going.&quot<br><br>  Rose smiles and replies, <br><br>&quot Jack, I believe in us. We've been through so much already, and I know that we can overcome anything that comes our way. I love you, and I'm grateful to have you by my side.&quot <br><br>"/>
                <img src="./static/images/titanic_3.png" onclick="showOutput2(this, 'model-output2')" content="HIGHLIGHT THE TITANIC SHIP: <span style='background-color: rgb(249, 246, 217);'>As the Titanic ship sails across the ocean, a couple stands on the deck</span>, gazing into each other's eyes. The man says, <br><br>&quot I'm so glad we're on this journey together. I<span style='background-color: rgb(249, 246, 217);'> promise to always protect and cherish you, no matter what challenges we may face.</span>&quot<br><br>  The woman responds, <br><br>&quot I feel the same way. I trust you with my life, and I know that we'll face whatever comes our way as a team.&quot<br><br>  As they embrace, the sun sets behind them, casting a warm glow on the scene, symbolizing the strength and love that binds them together.
              " />
              <p style="text-align: center">User: Write a dialog based on this image.</p>
                <!-- Model output -->
                <div id="model-output2">
                  <!-- The model output will be displayed here -->
                </div>
              </div>
          </div>
        </div>
      </section>

      <!-- <div class="column is-full-width"> -->
      <div class="content has-text-justified">
        <br>
        <h2 class="title is-3">Extensions</h2>
        <h3 class="title is-5">Free-form image-conditioned generation</h3>
        <p>
          In addition to its ability to generate images corresponding to the exemplar image and text
          prompts, we have also discovered that RIVAL has a strong ability to transfer styles and semantic
          concepts in the exemplar for a casual text-driven image generation.
          With RIVAL, we can easily get a style-specific text-to-image generation. For instance, it can
          produce a portrait painting of a robot adorned in a sailor uniform while faithfully preserving
          the stylistic characteristics inherent in the provided oil painting.
        </p>
        <img src="./static/images/free-form.png" style="padding: 5%;text-align:center; background:#fafafa" />
        <h3 class="title is-6">More examples (with the same prompt input and exemplar in the above image)</h3>

        <div class="container is-max-desktop">
          <section class="hero is-light is-small">
            <div class="hero-body">
              <div class="container" style="text-align:center">
                <div id="results-carousel" class="carousel results-carousel">
                  <div class="item item-exp1">
                    <img src="./static/images/girl_1.png" style="width:100%; " />
                  </div>
                  <div class="item item-exp2">
                    <img src="./static/images/girl_2.png" style="width:100%; " />
                  </div>
                  <div class="item item-exp3">
                    <img src="./static/images/girl_3.png" style="width:100%; " />
                  </div>
                </div>
              </div>
            </div>
          </section>
        </div>
        <!-- </div> -->
      </div>
      <!-- </div> -->
      <!--/ Adaptation to 2D Stylization. -->


      <!-- Appearance Editing. -->
      <div class="column has-text-justified" style="margin-right: 0%;">
        <br>
        <h3 class="title is-5">Example-based inpainting</h3>
        <p>
          When abstracting RIVAL as a novel paradigm of image-based diffusion inference, we can extend this
          framework to enable it to encompass other image editing tasks, such as inpainting. By incorporating
          a coarse mask <b>M</b> into the generation chain, we obtain the inpainted image <b>G</b>.
        </p>
        <img src="./static/images/inpaint.png" style="text-align:center;" />
      </div>
      <!--/ Appearance Editing. -->

      <!-- Controllability. -->
      <div class="column has-text-justified" style="margin-right: 0%;">
        <br>
        <h3 class="title is-5">Integration with concept customization</h3>
        <p>
          In addition to its ability to generate image variations from a single source image using a text
          prompt input for semantic alignment, RIVAL can be effectively combined with optimization-based
          concept customization techniques, such as DreamBooth, to enable novel concept customization.
        </p>
        <img src="./static/images/dreambooth.png" style="text-align:center;" />
      </div>
      <div class="column has-text-justified" style="margin-left: 0%;">
        <br>
        <h3 class="title is-5">Compare with UnCLIP</h3>
        <p>
          Comparision and adaptation with UnCLIP methods. We <b style="color:#cba320">highlight texts</b> that
          enhance the image understanding for each case. Our inference pipeline is adapted to the image
          variation model depicted in the fourth column, in contrast to the variation achieved through vanilla
          inference in the bottom left corner of each image.
        </p>
      </div>
      <div class="container is-max-desktop">
        <section class="hero is-light is-small">
          <div class="hero-body">
            <div class="container" style="text-align:center">
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item item-exp1">
                  <img src="./static/images/unclip_1.png" style="width:100%; " />
                </div>
                <div class="item item-exp2">
                  <img src="./static/images/unclip_2.png" style="width:100%; " />
                </div>
                <div class="item item-exp3">
                  <img src="./static/images/unclip_3.png" style="width:100%; " />
                </div>
                <div class="item item-exp4">
                  <img src="./static/images/unclip_4.png" style="width:100%; " />
                </div>
                <div class="item item-exp5">
                  <img src="./static/images/unclip_5.png" style="width:100%; " />
                </div>
              </div>
            </div>
          </div>
        </section>
      </div>
      <br>

      <div class="column has-text-justified is-centered" style="text-align:center">
        <br>
        <h3 class="title is-4">Methods</h3>
        <img src="./static/images/framework.png" style="width:100%;padding:7%" />
        <p>
          To address this distribution gap problem for generating image variations, we propose an inference pipeline
          called Real-world Image Variation by Alignment (RIVAL). RIVAL is a tunning-free approach that reduces the
          domain gap between the generated and real-world images by aligning the denoising chain with the real-image
          inversion chain. Our method comprises two key components: (i) a cross-image self-attention injection that
          enables cross-image feature interaction in the variation denoising chain, guided by the hidden states from the
          inversion chain, and (ii) a step-wise latent normalization that aligns the latent distribution with the
          inverted latent in early denoising steps. Notably, this modified inference process requires no training and is
          suitable for arbitrary image input.
        </p>
      </div>

      <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="title">BibTeX</h2>
          <pre><code>@article{zhang2023realworld,
  title={Real-World Image Variation by Aligning Diffusion Inversion Chain}, 
  author={Yuechen Zhang and Jinbo Xing and Eric Lo and Jiaya Jia},
  journal={arXiv preprint arXiv:2305.18729},
  year={2023},
}
      </code></pre>
        </div>
      </section>


      <footer class="footer">
        <div class="container">
          <div class="content has-text-centered">
            <a class="icon-link" href="" disabled>
              <i class="fas fa-file-pdf"></i>
            </a>
            <a class="icon-link external-link" href="https://rival-diff.github.io" disabled>
              <i class="ai ai-arxiv"></i>
            </a>
            <a class="icon-link external-link" href="https://github.com/julianjuaner/RIVAL/" disabled>
              <i class="fab fa-github"></i>
            </a>
          </div>
          <div class="columns is-centered">
            <div class="column is-8">
              <div class="content">
                <p>
                  This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
                <p>
                  Website template credit to <a href="https://nerfies.github.io/">Nerfies</a>.
                </p>
              </div>
            </div>
          </div>
        </div>
      </footer>

</body>

</html>