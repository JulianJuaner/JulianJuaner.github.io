<!DOCTYPE HTML>
<html lang="en"><head ><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>ZHANG Yuechen</title>
  
  <meta name="author" content="ZHANG Yuechen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü••</text></svg>">
</head>

<body>
  <table style="width:90%;max-width:1280px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        <!-- 1 INTRO -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="width:70%">
            <td style="padding:1%;vertical-align:middle">
              <p style="text-align:center">
                <name>ZHANG Yuechen, Julian ü••</name>
              </p>
              <p>
                Hi! Here is ZHANG Yuechen, Julian. I am a fourth-year Ph.D. student at <a href="https://www.cuhk.edu.hk/english/index.html"> CUHK</a>, advised by <a href="https://jiaya.me">Prof. Jiaya Jia</a>. I also join <a href="https://www.smartmore.com">SmartMore </a> as a computer vision developer.
              </p>
              <p>
                Before that, I received my B.Sc. degree at CUHK.
              </p>
              <p>
                My primary research interest is in controllable AIGC & VLM. Additionally, I have worked on several projects involving image segmentation.
              </p>
              <p>
                I will graduate in Dec 2025 and is open for job opportunities (ÁªôÂ≠©Â≠ê‰∏Ä‰∏™Â•ΩÂ∑•‰ΩúÂêß). Drop me an Email if you are recruiting!
              </p>
              <p style="text-align:center">
                <a href="mailto:zhangyc@link.cuhk.edu.hk">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=8OijNgkAAAAJ&hl">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/JulianJuaner">Github</a>
              </p>
            </td>
            <td style="padding:1%;vertical-align:middle;text-align:center" onmouseout="avator_stop()" onmouseover="avator_start()">
              <div class="one" style="display: inline;">
                <div class="two" id='avator' style="display: inline;">
                  <img style="width:100%;" src="images/IMG_2755.jpg">
                </div>
                <img style="width: 70%;" src="images/IMG_2755.jpg">
              </div>
              <script type="text/javascript">
                function avator_start() {
                  document.getElementById('avator').style.opacity = "1";
                }

                function avator_stop() {
                  document.getElementById('avator').style.opacity = "0";
                }
                avator_stop()
              </script>
            </td>
          </tr>
        </tbody></table>

        <!-- 2 Research -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Selected Research </heading>
                <br/>Hover the picture to see more
            </td>
          </tr>
          </tbody></table>
        <table style="width:100%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- 2.12 Jenga -->
          <tr class="single_element" style="width:70%">
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="jenga_stop()" onmouseover="jenga_start()">
              <div class="one" style="display: inline;vertical-align:middle;">
                <div class="two" id='jenga' style="display: inline;vertical-align:middle;">
                  <img src='images/jenga.png' max-width="360px" width="100%" vertical-align="middle">
                </div>
                <img src='images/jenga_default.gif' style="background-color: white;" max-width="360px" width="100%" vertical-align="middle">
              </div>
              <script type="text/javascript">
                function jenga_start() {
                  document.getElementById('jenga').style.opacity = "1";
                }

                function jenga_stop() {
                  document.getElementById('jenga').style.opacity = "0";
                }
                jenga_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>Training-Free Efficient Video Generation via Dynamic Token Carving</papertitle>
              <br>
              <a style="color:#ffac4d">Yuechen Zhang</a>, Jinbo Xing, Bin Xia, Shaoteng Liu, Bohao Peng, Xin Tao, Pengfei Wan, Eric Lo, Jiaya Jia
              <br>
              <p></p>
              <em>Preprint</em>, 2025
              <br>
              <a href="." target="blank_">arXiv</a> /
              <a href="projects/jenga/index.html" target="blank_">Project Page</a> / 
              <a href="https://github.com/dvlab-research/jenga">Code </a> 
              <!--<img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dvlab-research/jenga?style=social"> -->
            <p></p>
            <p style="font-size:16px;"><em>
              Jenga accelerates HunyuanVideo by 8.83√ó through dynamic attention carving and progressive resolution generation, enabling seconds-level high-quality video generation without model retraining.
              </em>
              </p>
            </td>
          </tr>
          <!-- 2.11 MagicMirror -->
          <tr class="single_element" style="width:70%">
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="magicmirror_stop()" onmouseover="magicmirror_start()">
              <div class="one" style="display: inline;vertical-align:middle;">
                <div class="two" id='magicmirror' style="display: inline;vertical-align:middle;">
                  <img src='images/magicmirror.png' max-width="360px" width="100%" vertical-align="middle">
                </div>
                <img src='images/magicmirror-default.gif' style="background-color: white;" max-width="360px" width="100%" vertical-align="middle">
              </div>
              <script type="text/javascript">
                function magicmirror_start() {
                  document.getElementById('magicmirror').style.opacity = "1";
                }

                function magicmirror_stop() {
                  document.getElementById('magicmirror').style.opacity = "0";
                }
                magicmirror_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>MagicMirror: ID-Preserved Video Generation in Video Diffusion Transformers</papertitle>
              <br>
              <a style="color:#ffac4d">Yuechen Zhang*</a>, Yaoyang Liu*, Bin Xia, Bohao Peng, Zexin Yan, Eric Lo, Jiaya Jia
              <br>
              <p></p>
              <em>Preprint</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2501.03931" target="blank_">arXiv</a> /
              <a href="projects/MagicMirror/index.html" target="blank_">Project Page</a> / 
              <a href="https://github.com/dvlab-research/MagicMirror">Code </a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dvlab-research/MagicMirror?style=social"> 
            <p></p>
            <p style="font-size:16px;"><em>
              Light passes through the Magic Mirror to create a personalized virtual world~ It generates identity-preserved videos from reference images using a conditional adaptive normalization module for faster convergence in video Diffusion Transformers.
              </em>
              </p>
            </td>
          </tr>

          <!-- 2.10 ControlNeXt -->
          <tr class="single_element" style="width:70%">
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="controlnext_stop()" onmouseover="controlnext_start()">
              <div class="one" style="display: inline;vertical-align:middle;">
                <div class="two" id='controlnext' style="display: inline;vertical-align:middle;">
                  <img src='images/controlnext.png' max-width="360px" width="100%" vertical-align="middle">
                </div>
                  <img src='images/controlnext-default.gif' max-width="360px" width="100%" vertical-align="middle">
              </div>
              <script type="text/javascript">
                function controlnext_start() {
                  document.getElementById('controlnext').style.opacity = "1";
                }

                function controlnext_stop() {
                  document.getElementById('controlnext').style.opacity = "0";
                }
                controlnext_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>ControlNeXt: Powerful and Efficient Control for Image and Video Generation</papertitle>
              <br>
               Bohao Peng, Jian Wang, <a style="color:#ffac4d">Yuechen Zhang</a>, Wenbo Li, Ming-Chang Yang, Jiaya Jia
              <br>
              <p></p>
              <em>Preprint</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2408.06070" target="blank_">arXiv</a> /
              <a href="https://pbihao.github.io/projects/controlnext/index.html" target="blank_">Project Page</a> / 
              <a href="https://huggingface.co/spaces/Eugeoter/ControlNeXt" target="blank_">Demo</a> /
              <a href="https://github.com/dvlab-research/ControlNeXt">Code </a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dvlab-research/ControlNeXt?style=social"> 
            <p></p>
            <p style="font-size:16px;"><em>
              This work proposes a light-weight controllable module for various base models (SD1.5, SDXL, SD3, SVD) and tasks (image / video generation with various conditions).
              </em>
              </p>
            </td>
          </tr>

          <!-- 2.9 Mini-Gemini -->
          <tr class="single_element" style="width:70%">
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="minigemini_stop()" onmouseover="minigemini_start()">
              <div class="one" style="display: inline;vertical-align:middle;">
                <div class="two" id='minigemini' style="display: inline;vertical-align:middle;">
                  <img src='images/minigemini.png' max-width="360px" width="100%" vertical-align="middle">
                </div>
                  <img src='images/minigemini-default.png' max-width="360px" width="100%" vertical-align="middle">
              </div>
              <script type="text/javascript">
                function minigemini_start() {
                  document.getElementById('minigemini').style.opacity = "1";
                }

                function minigemini_stop() {
                  document.getElementById('minigemini').style.opacity = "0";
                }
                minigemini_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models</papertitle>
              <br>
               Yanwei Li*, <a style="color:#ffac4d">Yuechen Zhang*</a>, Chengyao Wang*, Zhisheng Zhong, Yixin Chen, Ruihang Chu, Shaoteng Liu, Jiaya Jia
              <br>
              <p></p>
              <em>Preprint</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2403.18814" target="blank_">arXiv</a> /
              <a href="https://mini-gemini.github.io/" target="blank_">Project Page</a> / 
              <a href="http://10.81.134.110:7860/" target="blank_">Demo</a> /
              <a href="https://huggingface.co/collections/YanweiLi/mini-gemini-6603c50b9b43d044171d0854" target="blank_">Model</a> /
              <a href="https://huggingface.co/collections/YanweiLi/mini-gemini-data-660463ea895a01d8f367624e" target="blank_">Data</a> /
              <a href="https://github.com/dvlab-research/MiniGemini">Code </a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dvlab-research/MiniGemini?style=social"> 
            <p></p>
            <p style="font-size:16px;"><em>
              Mining potential of open-source VLMs! Mini-Gemini is a novel framework ranges from 2B to 34B VLMs for hi-resolution image understanding. It has a impressive OCR capability, and can generate HQ images powered by its multi-modal reasoning ability.
              </em>
              </p>
            </td>
          </tr>

          <!-- 2.8 Prompt Highlighter -->
          <tr class="single_element" style="width:70%">
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="ph_stop()" onmouseover="ph_start()">
              <div class="one" style="display: inline;vertical-align:middle;">
                <div class="two" id='ph' style="display: inline;vertical-align:middle;">
                  <img src='images/ph.png' max-width="360px" width="100%" vertical-align="middle">
                </div>
                  <img src='images/ph-default.png' max-width="360px" width="100%" vertical-align="middle">
              </div>
              <script type="text/javascript">
                function ph_start() {
                  document.getElementById('ph').style.opacity = "1";
                }

                function ph_stop() {
                  document.getElementById('ph').style.opacity = "0";
                }
                ph_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>Prompt Highlighter: Interactive Control for Multi-Modal LLMs</papertitle>
              <br>
              <a style="color:#ffac4d">Yuechen Zhang</a>, Shengju Qian, 
              Bohao Peng, Shu Liu, Jiaya Jia
              <br>
              <p></p>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2312.04302" target="blank_">arXiv</a> /
              <a href="projects/PromptHighlighter/" target="blank_">Project Page</a> / 
              <a href="https://github.com/dvlab-research/Prompt-Highlighter/">Code </a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dvlab-research/Prompt-Highlighter?style=social"> 
            <p></p>
            <p style="font-size:16px;"><em>
              Control text generation by highlighting our prompt! Prompt Highlighter is a training-free inference pipeline, which facilitates token-level user interactions for customized generation. Our method is compatible for both LLMs and VLMs.
              </em>
              </p>
            </td>
          </tr>

          <!-- 2.7 RIVAL -->
          <tr class="single_element" style="width:70%">
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="rival_stop()" onmouseover="rival_start()">
              <div class="one" style="display: inline;vertical-align:middle;">
                <div class="two" id='rival' style="display: inline;vertical-align:middle;">
                  <img src='images/rival.png' max-width="360px" width="100%" vertical-align="middle">
                </div>
                  <img src='images/rival-default.png' max-width="360px" width="100%" vertical-align="middle">
              </div>
              <script type="text/javascript">
                function rival_start() {
                  document.getElementById('rival').style.opacity = "1";
                }

                function rival_stop() {
                  document.getElementById('rival').style.opacity = "0";
                }
                rival_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>Real-World Image Variation by Aligning Diffusion Inversion Chain</papertitle>
              <br>
              <a style="color:#ffac4d">Yuechen Zhang</a>, Jinbo Xing, 
              Eric Lo, Jiaya Jia
              <br>
              <p></p>
              <em>NeurIPS <a style="color:#ffac4d">(Spotlight)</a></em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2305.18729" target="blank_">arXiv</a> /
              <a href="https://rival-diff.github.io/" target="blank_">Project Page</a> / 
              <a href="https://github.com/julianjuaner/RIVAL/">Code </a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/julianjuaner/RIVAL?style=social"> 
            <p></p>
            <p style="font-size:16px;"><em>
               Given an image as the prompt, we can generate its variations by aligning the diffusion inversion chain. The variations are diverse and controllable.
              </em>
              </p>
            </td>
          </tr>

          <!-- 2.6 Video-P2P-->
          <tr class="single_element" style="width:70%">
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="videop2p_stop()" onmouseover="videop2p_start()">
              <div class="one" style="display: inline;vertical-align:middle;">
                <div class="two" id='videop2p' style="display: inline;vertical-align:middle;">
                  <img src='images/videop2p.png' max-width="360px" width="100%" vertical-align="middle">
                </div>
                  <img src='images/videop2p.gif' max-width="360px" width="100%" vertical-align="middle">
              </div>
              <script type="text/javascript">
                function videop2p_start() {
                  document.getElementById('videop2p').style.opacity = "1";
                }

                function videop2p_stop() {
                  document.getElementById('videop2p').style.opacity = "0";
                }
                videop2p_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>Video-P2P: Video Editing with Cross-attention Control</papertitle>
              <br>
              Shaoteng Liu, <a style="color:#ffac4d">Yuechen Zhang</a>, Wenbo Li, 
              Zhe Lin, Jiaya Jia
              <br>
              <p></p>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2303.04761" target="blank_">arXiv</a> / 
              <a href="https://video-p2p.github.io/" target="blank_">Project Page</a> / 
              <a href="https://github.com/ShaoTengLiu/Video-P2P">Code</a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/ShaoTengLiu/Video-P2P?style=social"> 
            <p></p>
            <p style="font-size:16px;"><em>
               Add 'Lego' attribute to the child, an edited video is generated. Powered by a novel video inversion process and cross-attention control. We also find that a Decoupled-Guidance strategy is essential for video editing.
              </em>
              </p>
            </td>
          </tr>
          
          <!-- 2.5 Ref-NPR-->
          <tr class="single_element" >
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="refnpr_stop()" onmouseover="refnpr_start()">
              <div class="one" style="display: inline;">
                <div class="two" id='refnpr' style="display: inline;">
                  <img src='images/ref-npr.png' max-width="360px" width="100%">
                </div>
                <img src='images/ref-npr-default.gif' max-width="360px" width="100%">
              </div>
              <script type="text/javascript">
                function refnpr_start() {
                  document.getElementById('refnpr').style.opacity = "1";
                }

                function refnpr_stop() {
                  document.getElementById('refnpr').style.opacity = "0";
                }
                refnpr_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>Ref-NPR: Reference-Based Non-Photorealistic Radiance Fields</papertitle>
              <br>
              <a style="color:#ffac4d">Yuechen Zhang</a>, 
              Zexin He, Jinbo Xing, Xufeng Yao, Jiaya Jia 
              <br>
              <p></p>
              <em>CVPR</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2212.02766" target="blank_">arXiv</a>
              /
              <a href="https://ref-npr.github.io" target="blank_">Project Page</a>
              / 
              <a href="https://github.com/dvlab-research/Ref-NPR">Code</a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dvlab-research/Ref-NPR?style=social"> 
            <p></p>
            <p style="font-size:16px;"><em>
                We present a controllable scene stylization method utilizing radiance fields to stylize a 3D scene, with a single stylized 2D view taken as reference.
              </em>
              </p>
            </td>
          </tr>


          <!-- 2.4 CodeTalker-->
          <tr class="single_element" >
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="codetalker_stop()" onmouseover="codetalker_start()">
              <div class="one" style="display: inline;">
                <div class="two" id='codetalker' style="display: inline;">
                  <video max-width="360px" width="100%" muted autoplay loop>
                    <source src="images/codetalker_video.mp4" alt="Annimation for codetalker" width="480" width="100%" type="video/mp4">
                  </video>
                </div>
                  <img src='images/codetalker.png' max-width="360px" width="100%">
              </div>
              <script type="text/javascript">
                function codetalker_start() {
                  document.getElementById('codetalker').style.opacity = "1";
                }

                function codetalker_stop() {
                  document.getElementById('codetalker').style.opacity = "0";
                }
                codetalker_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior</papertitle>
              <br>
              Jinbo Xing, Menghan Xia, <a style="color:#ffac4d">Yuechen Zhang</a>, 
              Xiaodong Cun, Jue Wang, Tien-Tsin Wong
              <br>
              <p></p>
              <em>CVPR</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2301.02379" target="blank_">arXiv</a> / 
              <a href="https://doubiiu.github.io/projects/codetalker/" target="blank_">Project Page</a>/ 
              <a href="https://github.com/Doubiiu/CodeTalker">Code</a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/Doubiiu/CodeTalker?style=social"> 
            <p></p>
            <p style="font-size:16px;"><em>
               A speech input generates an authentic 3D facial animation based on representations with discrete motion prior.
              </em>
              </p>
            </td>
          </tr>
          <!-- 2.3 R^2 -->
          <tr class="single_element">
            <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="r2_stop()" onmouseover="r2_start()">
              <div class="one" style="display: inline;">
                <div class="two" id='r2_image' style="display: inline;">
                  <img src='images/r2.png' max-width="360px" width="100%">
                </div>
                <img src='images/r2-default.png' max-width="360px" width="100%">
              </div>
              <script type="text/javascript">
                function r2_start() {
                  document.getElementById('r2_image').style.opacity = "1";
                }
                function r2_stop() {
                  document.getElementById('r2_image').style.opacity = "0";
                }
                r2_stop()
              </script>
            </td>
            <td style="padding:20px;vertical-align:middle">
                <papertitle>R<sup>2</sup>Former: Probing Region Relationship in Semantic Segmentation Transformers</papertitle>
              </a>
              <br>
              <a style="color:#ffac4d">Yuechen Zhang</a>, 
              Tiancheng Shen*, Huaijia Lin, Lu Qi, Eric Lo, Jiaya Jia 
              <br>
              <p></p>
              <em>Preprint</em>, 2022
              <br>
              <p></p>
              <p style="font-size:16px;"><em>
                R<sup>2</sup>Former decomposes the relationships into intra-region ones and inter-region ones. With such modifications, the performance of mask classification can be improved on widely used semantic segmentation benchmarks.
              </em></p>
            </td>
          </tr>

        <!-- 2.2  CRM-->
        <tr class="single_element">
          <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="crm_stop()" onmouseover="crm_start()">
            <div class="one" style="display: inline;">
              <div class="two" id='crm_image' style="display: inline;">
                <img src='images/crm.png' max-width="360px" width="100%">
              </div>
              <img src='images/crm-default.png' max-width="360px" width="100%">
            </div>
            <script type="text/javascript">
              function crm_start() {
                document.getElementById('crm_image').style.opacity = "1";
              }
              function crm_stop() {
                document.getElementById('crm_image').style.opacity = "0";
              }
              crm_stop()
            </script>
          </td>
          <td style="padding:20px;vertical-align:middle">
              <papertitle>High Quality Segmentation for Ultra High-resolution Images</papertitle>
            </a>
            <br>
            Tiancheng Shen, 
            <a style="color:#ffac4d">Yuechen Zhang</a>, 
            Lu Qi, Jason Kuen, Xingyu Xie, Jianlong Wu, Zhe Lin, Jiaya Jia
            <br>
            <p></p>
            <em>CVPR</em>, 2022
            <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_High_Quality_Segmentation_for_Ultra_High-Resolution_Images_CVPR_2022_paper.pdf">Paper</a> 
              / 
              <a href="https://github.com/dvlab-research/Entity/tree/main/High-Quality-Segmention">Code</a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dvlab-research/Entity?style=social"> 
              <p></p>
            <p style="font-size:16px;"><em>
              We propose the Continuous Refinement Model (CRM) for the ultra high-resolution mask refinement. CRM aligns the feature with the refinement target and aggregates them to reconstruct image details.
            </em></p>
          </td>
        </tr>

        <!-- 2.1 PCL-->
        <tr class="single_element">
          <td style="padding:20px;vertical-align:middle;text-align:middle" onmouseout="pcl_stop()" onmouseover="pcl_start()">
            <div class="one" style="display: inline;">
              <div class="two" id='pcl_image' style="display: inline;">
                <img src='images/pcl.png' max-width="360px" width="100%">
              </div>
              <img src='images/pcl-default.png' max-width="360px" width="100%">
            </div>
            <script type="text/javascript">
              function pcl_start() {
                document.getElementById('pcl_image').style.opacity = "1";
              }
              function pcl_stop() {
                document.getElementById('pcl_image').style.opacity = "0";
              }
              pcl_stop()
            </script>
          </td>
          <td style="padding:20px;vertical-align:middle">
              <papertitle>PCL: Proxy-based Contrastive Learning for Domain Generalization</papertitle>
            </a>
            <br>
            Xufeng Yao, Yang Bai, Xinyun Zhang,
            <a style="color:#ffac4d">Yuechen Zhang</a>, 
            Qi Sun, Ran Chen, Ruiyu Li, Bei Yu
            <br>
            <p></p>
            <em>CVPR</em>, 2022
            <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yao_PCL_Proxy-Based_Contrastive_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf">Paper</a> 
              / 
              <a href="https://github.com/yaoxufeng/PCL-Proxy-based-Contrastive-Learning-for-Domain-Generalization">Code</a> 
              <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/yaoxufeng/PCL-Proxy-based-Contrastive-Learning-for-Domain-Generalization?style=social"> 
              <p></p>
            <p style="font-size:16px;"><em>
              We propose a novel proxy-based contrastive learning method, which replaces the original sample-to-sample relations with proxy-to-sample relations, significantly alleviating the positive alignment issue.
            </em></p>
          </td>
        </tr>
          
        </tbody></table>

        <p></p>
        <!-- 2-x Other Projects -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:1%;width:100%;vertical-align:middle">
            <heading>Other Projects</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td class="single_element" style="padding:20px;vertical-align:top;text-align:middle">
            <div class="one" style="display: inline;">
                <img src='images/cvm.png' width="100%">
            </div>
            <br>
            <a style="color:#ffac4d"><strong>
              Flow-aware synthesis: A generic motion model for video frameinterpolation
            </strong></a>
            <a href="https://link.springer.com/content/pdf/10.1007/s41095-021-0208-x.pdf"> Paper </a>
            <p> <em>Computational Visual Media, 2021</em>. Jinbo Xing, Wenbo Hu, <a style="color:#ffac4d">Yuechen Zhang</a>, Tien-Tsin Wong
          </td>

          <td class="single_element" style="padding:20px;vertical-align:top;text-align:middle">
            <div class="one" style="display: inline;">
                <img src='images/fsglyph.png' width="100%">
            </div>
            <br>
            <a style="color:#ffac4d"><strong>ESTR4999: Few-Shot Glyph Style Transfer</strong></a>
            <br>
            <a href="https://github.com/JulianJuaner/FSGlyphST"> Code </a>
            <p></p>
            <p> <em>CUHK FYP</em>. Supervised by Tien-Tsin Wong.
          </td>
          <td class="single_element" style="padding:20px;vertical-align:top;text-align:middle">
            <div class="one" style="display: inline;">
                <img src='images/protraitST.png' width="100%">
            </div>
            <br>
            <a style="color:#ffac4d"><strong>
            ESTR4998: Protrait Style Transfer
            </strong></a>
            <br>
            <a href="https://github.com/JulianJuaner/PortraitST"> Code </a>
            <p> <em>CUHK FYP</em>. Collaborated with Jinbo Xing, supervised by Tien-Tsin Wong.
          </td>
        </tr>
      
      </tbody></table>


        <!-- 3 Experiences -->
        <table style="width:100%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Experiences</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr >
              <td style="padding:10px;text-align:left">
                <b>SmartMore Corporation Limited</b>
              </td>
              <td style="padding:0px;text-align:left">
                <em>Computer Vision Developer</em>
                <br>
                Mentor: <a href="http://shuliu.me/">Shu Liu</a>
              </td>
              <td style="padding:0px;;text-align:right">
                <strong>Jan. 2020 - Present</strong>
              </td>
            </tr>
            <tr>
              <td style="padding:10px;text-align:left">
                <b>The Chinese University of Hong Kong</b>
              </td>
              <td style="padding:0px;text-align:left">
                <em>Bachelor of Computer Science</em>
                <br>
                Supervisor: <a href="https://www.cse.cuhk.edu.hk/~ttwong">Tien-Tsin Wong</a>
              </td>
              <td style="padding:0px;;text-align:right">
                <strong>Sep. 2016 - Jul. 2021</strong>
              </td>
            </tr>
            <tr>
              <td style="padding:10px;text-align:left">
                <b>Nanyang Technological University</b>
              </td>
              <td style="padding:0px;text-align:left">
                <em>GEM Trailblazer Exchange Program</em>
              </td>
              <td style="padding:0px;;text-align:right">
                <strong>Jan. 2019 - May. 2019</strong>
              </td>
            </tr>
          </tbody>
        </table>

				<p></p>
        
        <!-- 4 HonorsAndAwards -->
        <table style="width:100%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Selected Awards</heading>
            </td>
          </tr>
        </tbody></table>
          <ul>
            <li><p>
              CUHK ELITE Stream Scholarship, <b>2017, 2018</b>
            </p></li>
            <li><p>
              CUHK CSE Academic Outstanding Award, <b>2018, 2019, 2020</b>
            </p></li>
            <li><p>
              CUHK Faculty of Engineering, Dean‚Äôs List, <b>2017, 2018</b>
            </p></li>
            <li><p>
              CWChu College Scholarships for Academic Excellence, <b>2018, 2019, 2020</b>
            </p></li>
          </ul>
        
        <p></p>

        <!-- 5 Teaching -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="border-spacing:10px 0px;">
          <tbody>
            <tr>
              <td style="padding:10px;text-align:left">
                CSCI3280 <b>|</b> Introduction to Multimedia Systems <b>|</b> 2023 Spring
	     </td>
            </tr>   
	    <tr>
              <td style="padding:10px;text-align:left">
		ESTR4998 <b>|</b> Final Year Thesis <b>|</b> 2024-2025
              </td>
            </tr>
          </tbody>
        </table>
	<!-- 6 Reviewer -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Reviewer</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="border-spacing:10px 0px;">
          <tbody>
            <tr>
              <td style="padding:10px;text-align:left">
                2024 <b>|</b> CVPR, NeurIPS, ECCV, AAAI
	       </td>
            </tr>   
	    <tr>
              <td style="padding:10px;text-align:left">
		2023 <b>|</b> AAAI
              </td>
            </tr>
          </tbody>
        </table>
	
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Page Views</heading>
            </td>
          </tr>
          <tr>
            <td style="padding:10%;width:50%;vertical-align:middle">
              <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=pUXiGSWRZAOMyV4HZ4k_qeaaEmRtei5Nbmuno6ABr_o&cl=ffffff&w=a"></script> 
            </td>
        </tr>
      </tbody></table> -->
        <!-- 6 Ending -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Last updated: Nov 2022
                <br>
                Web page design credit to <a href="https://jonbarron.info" style="font-size: 14px">Jon Barron</a> and <a href="https://zxhezexin.com/" style="font-size: 14px">Zexin He</a>
                <br>
                Avatar style credit to <a href="https://www.shaotengliu.com/" style="font-size: 14px">Shaoteng Liu</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      
      </td>
    </tr>
  </table>
</body>

</html>
