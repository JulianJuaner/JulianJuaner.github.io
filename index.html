<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>ZHANG Yuechen</title>
  <meta name="author" content="ZHANG Yuechen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet_new.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü••</text></svg>">
</head>

<body>
  <!-- Âø´ÈÄüÂØºËà™Ê†è -->
  <nav class="fast-nav">
    <div class="nav-container">
      <div class="nav-title">YUECHEN ZHANG's WEBPAGE</div>
      <div class="nav-links">
        <a href="#about" class="nav-link">About</a>
        <a href="#representative" class="nav-link">Highlights</a>
        <a href="#publications" class="nav-link">Publications</a>
        <a href="#education" class="nav-link">Experience</a>
        <a href="#awards" class="nav-link">Awards</a>
      </div>
    </div>
  </nav>


  <!-- Â§¥ÈÉ®Âå∫Âüü -->
  <div id="about" class="header-container">
    <span class="header-motion-hint header-motion-hint-top">Double-click to toggle motion / ÂèåÂáªÂàáÊç¢Âä®Êïà</span>
    <div class="header-motion-controls">
      <button class="header-motion-toggle" type="button" aria-pressed="true">Motion On</button>
    </div>
    <div class="header-pattern header-pattern-base" aria-hidden="true"></div>
    <div class="header-content-stack">
      <div class="header-content header-content-base">
        <div class="header-text">
          <h1 class="header-title">ZHANG Yuechen</h1>
          <p class="header-description">
            Hi! I am a Research Scientist in Multi-Modal at <a href="https://mimo.xiaomi.com/">Xiaomi MiMo</a>.
            <br><br>
            I graduated from <a href="https://www.cuhk.edu.hk/english/index.html">CUHK</a> in 2025, advised by <a href="https://jiaya.me">Prof. Jiaya Jia</a>.
            Before that, I received my bachelor's degree from <a href="https://www.cuhk.edu.hk/english/index.html">CUHK</a> in 2021.
            I focus on <strong>autoregressive, interactive, and efficient video generation and intelligence</strong>.
            I also enjoy exploring <strong>special and interesting visual effects and applications</strong> in generation tasks.
          </p>
          <div class="header-links">
            <a href="mailto:zhangyc@link.cuhk.edu.hk" class="header-link">Email</a>
            <a href="https://scholar.google.com/citations?user=8OijNgkAAAAJ&hl" class="header-link">Google Scholar</a>
            <a href="https://github.com/JulianJuaner" class="header-link">Github</a>
          </div>
        </div>
        <div class="header-image" aria-hidden="true">
          <br>
          <img src="images/IMG_2755_2_dark.png" alt="">
          <br>
          <img src="images/interests_2_dark.png" alt="">
        </div>
      </div>
    </div>
    <div class="header-mask-layer" aria-hidden="true">
      <div class="header-pattern"></div>
      <div class="header-content header-content-masked">
        <div class="header-text">
          <h1 class="header-title">HiÔºÅÊàëÊòØÂº†Â≤≥Êô®</h1>
          <p class="header-description">
            ‰Ω†Â•ΩÔºÅÊàëÁõÆÂâçÊòØ <a href="https://mimo.xiaomi.com/">Â∞èÁ±≥ MiMo (LLM-Core)</a> ÁöÑÂ§öÊ®°ÊÄÅÁÆóÊ≥ïÁ†îÁ©∂Âëò„ÄÇ
            <br><br>
            Êàë‰∫é 2025 Âπ¥ÊØï‰∏ö‰∫é <a href="https://www.cuhk.edu.hk/english/index.html">È¶ôÊ∏Ø‰∏≠ÊñáÂ§ßÂ≠¶</a>ÔºåÂØºÂ∏à‰∏∫ <a href="https://jiaya.me">Ë¥æ‰Ω≥‰∫öÊïôÊéà</a>„ÄÇ
            Âú®Ê≠§‰πãÂâçÔºåÊàë‰∫é 2021 Âπ¥Ëé∑Âæó <a href="https://www.cuhk.edu.hk/english/index.html">È¶ôÊ∏Ø‰∏≠ÊñáÂ§ßÂ≠¶</a> ÁöÑËÆ°ÁÆóÊú∫ÁßëÂ≠¶Â≠¶Â£´Â≠¶‰Ωç„ÄÇ
            Á†îÁ©∂ÊñπÂêëËÅöÁÑ¶ <strong>Ëá™ÂõûÂΩí„ÄÅ‰∫§‰∫íÂºè„ÄÅÈ´òÊïàÁöÑËßÜÈ¢ëÁîüÊàê‰∏éÊô∫ËÉΩ</strong>„ÄÇ
            ‰πüÂñúÊ¨¢Êé¢Á¥¢ÁîüÊàê‰ªªÂä°‰∏≠ÁöÑ <strong>ÁâπÊÆä‰∏îÊúâË∂£ÁöÑËßÜËßâÊïàÊûú‰∏éÂ∫îÁî®</strong>„ÄÇ
          </p>
          <div class="header-links">
            <a href="mailto:zhangyc@link.cuhk.edu.hk" class="header-link">ÈÇÆÁÆ±</a>
            <a href="https://scholar.google.com/citations?user=8OijNgkAAAAJ&hl" class="header-link">Ë∞∑Ê≠åÂ≠¶ÊúØ</a>
            <a href="https://github.com/JulianJuaner" class="header-link">‰ª£Á†Å</a>
          </div>
        </div>
        <div class="header-image">
          <br>
          <img src="images/IMG_2755_2.png" alt="ZHANG Yuechen">
          <br>
          <img src="images/interests_2.png" alt="research interests">
        </div>
      </div>
    </div>
    </div>
    <span class="header-motion-hint header-motion-hint-bottom">Double-click to toggle motion / ÂèåÂáªÂàáÊç¢Âä®Êïà</span>
    <!-- <div class="header-research-interests">
      <p class="research-interests-text">
        I am interested in <strong>autoregressive, interactive, and efficient video generation and intelligence</strong>. <br>
        I am also interested in <strong>special and interesting visual effects and applications</strong> in generation tasks
      </p>
    </div> -->
    <!-- <div class="header-bottom-image">
      <img class="image-center image-landscape" src="image.png" alt="ZHANG Yuechen">
      <img class="image-center image-portrait" src="image_ver.png" alt="ZHANG Yuechen">
    </div> -->
  </div>
  <!-- Representative Works ÈÉ®ÂàÜ -->
  <section id="representative" class="works-section">
    <h2 class="section-title">Representative Research Works</h2>
    <!-- insert image.png into the page.-->
    <div class="works-list">
      <!-- Jenga -->
      <div class="bigcard">
        <div class="bigcard-img-wrap hover-img-box">
          <img src="posters/jenga.png" alt="Jenga" class="bigcard-img img-default" />
          <img src="images/jenga_default.gif" alt="Jenga" class="bigcard-img img-hover" />
        </div>
        <div class="bigcard-content">
          <div>
            <div class="bigcard-title">Training-Free Efficient Video Generation via Dynamic Token Carving</div>
            <div class="bigcard-authors"><span class="author-name">Yuechen Zhang</span>, Jinbo Xing, Bin Xia, Shaoteng Liu, Bohao Peng, Xin Tao, Pengfei Wan, Eric Lo, Jiaya Jia</div>
            <div class="bigcard-venue">NeurIPS, 2025</div>
            <div class="bigcard-desc">Jenga accelerates HunyuanVideo by 4.68-10.35√ó through dynamic attention carving and progressive resolution generation.</div>
          </div>
          <div class="bigcard-links">
              <a href="https://arxiv.org/abs/2505.16864" class="bigcard-link">arXiv</a>
              <a href="projects/jenga/index.html" class="bigcard-link">Project</a>
              <a href="https://github.com/dvlab-research/Jenga" class="bigcard-link">Code </a> 
            </div>
        </div>
      </div>

      <!-- MagicMirror -->
      <div class="bigcard">
        <div class="bigcard-img-wrap hover-img-box">
          <img src="posters/mg.png" alt="MagicMirror" class="bigcard-img img-default" />
          <img src="images/magicmirror-default.gif" alt="MagicMirror" class="bigcard-img img-hover" />
        </div>
        <div class="bigcard-content">
          <div>
            <div class="bigcard-title">MagicMirror: ID-Preserved Video Generation in Video Diffusion Transformers</div>
            <div class="bigcard-authors"><span class="author-name">Yuechen Zhang*</span>, Yaoyang Liu*, Bin Xia, Bohao Peng, Zexin Yan, Eric Lo, Jiaya Jia</div>
            <div class="bigcard-venue">ICCV, 2025</div>
            <div class="bigcard-desc">MagicMirror generates identity-preserved videos from reference images using a conditional adaptive normalization module.</div>
          </div>
          <div class="bigcard-links">
            <a href="https://arxiv.org/abs/2501.03931" class="bigcard-link">arXiv</a>
            <a href="projects/MagicMirror/index.html" class="bigcard-link">Project</a>
            <a href="https://github.com/dvlab-research/MagicMirror" class="bigcard-link">Code</a>
          </div>
        </div>
      </div>

      <!-- Mini-Gemini -->
      <div class="bigcard">
        <div class="bigcard-img-wrap hover-img-box">
          <img src="posters/mgm.png" alt="Mini-Gemini" class="bigcard-img img-default" />
          <img src="images/minigemini.png" alt="Mini-Gemini" class="bigcard-img img-hover" />
        </div>
        <div class="bigcard-content">
          <div>
            <div class="bigcard-title">Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models</div>
            <div class="bigcard-authors">Yanwei Li*, <span class="author-name">Yuechen Zhang*</span>, Chengyao Wang*, Zhisheng Zhong, Yixin Chen, Ruihang Chu, Shaoteng Liu, Jiaya Jia</div>
            <div class="bigcard-venue">TPAMI, 2025</div>
            <div class="bigcard-desc">Mini-Gemini is a novel framework ranges from 2B to 34B VLMs for hi-resolution image understanding and reasoning-aware image generation.</div>
          </div>
          <div class="bigcard-links">
            <a href="https://arxiv.org/abs/2403.18814" class="bigcard-link">arXiv</a>
            <a href="https://mini-gemini.github.io/" class="bigcard-link">Project</a>
            <a href="https://github.com/dvlab-research/MiniGemini" class="bigcard-link">Code</a>
          </div>
        </div>
      </div>

      <!-- Prompt Highlighter -->
      <div class="bigcard">
        <div class="bigcard-img-wrap hover-img-box">
          <img src="posters/ph.png" alt="Prompt Highlighter" class="bigcard-img img-default" />
          <img src="images/ph.png" alt="Prompt Highlighter" class="bigcard-img img-hover" />
        </div>
        <div class="bigcard-content">
          <div>
            <div class="bigcard-title">Prompt Highlighter: Interactive Control for Multi-Modal LLMs</div>
            <div class="bigcard-authors"><span class="author-name">Yuechen Zhang</span>, Shengju Qian, Bohao Peng, Shu Liu, Jiaya Jia</div>
            <div class="bigcard-venue">CVPR, 2024</div>
            <div class="bigcard-desc">Prompt Highlighter is a training-free inference pipeline, which facilitates token-level user interactions for customized generation.</div>
          </div>
          <div class="bigcard-links">
            <a href="https://arxiv.org/abs/2312.04302" class="bigcard-link">arXiv</a>
            <a href="projects/PromptHighlighter/" class="bigcard-link">Project</a>
            <a href="https://github.com/dvlab-research/Prompt-Highlighter/" class="bigcard-link">Code</a>
          </div>
        </div>
      </div>

      <!-- RIVAL -->
      <div class="bigcard">
        <div class="bigcard-img-wrap hover-img-box">
          <img src="posters/rival.png" alt="RIVAL" class="bigcard-img img-default" />
          <img src="images/rival-default.png" alt="RIVAL" class="bigcard-img img-hover" />
        </div>
        <div class="bigcard-content">
          <div>
            <div class="bigcard-title">Real-World Image Variation by Aligning Diffusion Inversion Chain</div>
            <div class="bigcard-authors"><span class="author-name">Yuechen Zhang</span>, Jinbo Xing, Eric Lo, Jiaya Jia <br/> <br/></div>
            <div class="bigcard-venue">NeurIPS (Spotlight), 2023</div>
            <div class="bigcard-desc">Given an image as the prompt, we can generate its variations by aligning the diffusion inversion chain. The variations are diverse and controllable.</div>
          </div>
          <div class="bigcard-links">
            <a href="https://arxiv.org/abs/2305.18729" class="bigcard-link">arXiv</a>
            <a href="https://rival-diff.github.io/" class="bigcard-link">Project</a>
            <a href="https://github.com/julianjuaner/RIVAL/" class="bigcard-link">Code</a>
          </div>
        </div>
      </div>

      <!-- Ref-NPR -->
      <div class="bigcard">
        <div class="bigcard-img-wrap hover-img-box">
          <img src="posters/refnpr.png" alt="Ref-NPR" class="bigcard-img img-default" />
          <img src="images/ref-npr-default.gif" alt="Ref-NPR" class="bigcard-img img-hover" />
        </div>
        <div class="bigcard-content">
          <div>
            <div class="bigcard-title">Ref-NPR: Reference-Based Non-Photorealistic Radiance Fields</div>
            <div class="bigcard-authors"><span class="author-name">Yuechen Zhang</span>, Zexin He, Jinbo Xing, Xufeng Yao, Jiaya Jia</div>
            <div class="bigcard-venue">CVPR, 2023</div>
            <div class="bigcard-desc">We present a controllable scene stylization method utilizing radiance fields to stylize a 3D scene, with a single stylized 2D view taken as reference.</div>
          </div>
          <div class="bigcard-links">
            <a href="https://arxiv.org/abs/2212.02766" class="bigcard-link">arXiv</a>
            <a href="https://ref-npr.github.io" class="bigcard-link">Project</a>
            <a href="https://github.com/dvlab-research/Ref-NPR" class="bigcard-link">Code</a>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Full Publications ÈÉ®ÂàÜ -->
  <section id="publications" class="publications-section">
    <h2 class="section-title">Full Publications</h2>
    <div class="publications-list">
      <!-- Jenga -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/jenga_default.gif" alt="Jenga" class="pub-img-default" />
          <img src="images/jenga.png" alt="Jenga" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">Training-Free Efficient Video Generation via Dynamic Token Carving</div>
          <div class="publication-authors"><span class="author-name">Yuechen Zhang</span>, Jinbo Xing, Bin Xia, Shaoteng Liu, Bohao Peng, Xin Tao, Pengfei Wan, Eric Lo, Jiaya Jia</div>
          <div class="publication-venue">NeurIPS, 2025</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2505.16864">arXiv</a> /
            <a href="projects/jenga/index.html">Project</a> /
            <a href="https://github.com/dvlab-research/Jenga" class="code-link" data-github-repo="dvlab-research/Jenga">Code</a><span class="github-stars" data-github-repo="dvlab-research/Jenga"></span>
          </div>
        </div>
      </div>

      <!-- MagicMirror -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/magicmirror-default.gif" alt="MagicMirror" class="pub-img-default" />
          <img src="images/magicmirror.png" alt="MagicMirror" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">MagicMirror: ID-Preserved Video Generation in Video Diffusion Transformers</div>
          <div class="publication-authors"><span class="author-name">Yuechen Zhang*</span>, Yaoyang Liu*, Bin Xia, Bohao Peng, Zexin Yan, Eric Lo, Jiaya Jia</div>
          <div class="publication-venue">ICCV, 2025</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2501.03931">arXiv</a> /
            <a href="projects/MagicMirror/index.html">Project</a> /
            <a href="https://github.com/dvlab-research/MagicMirror" class="code-link" data-github-repo="dvlab-research/MagicMirror">Code</a><span class="github-stars" data-github-repo="dvlab-research/MagicMirror"></span>
          </div>
        </div>
      </div>

      <!-- Lyra -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/lyra-default.png" alt="Lyra" class="pub-img-default" />
          <img src="images/lyra.png" alt="Lyra" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">Lyra: An Efficient and Speech-Centric Framework for Omni-Cognition</div>
          <div class="publication-authors">Zhisheng Zhong*, Chengyao Wang*, Yuqi Liu*, Senqiao Yang, Longxiang Tang, <span class="author-name">Yuechen Zhang</span>, Jingyao Li, Tianyuan Qu, Yanwei Li, Yukang Chen, Shaozuo Yu, Sitong Wu, Eric Lo, Shu Liu, Jiaya Jia</div>
          <div class="publication-venue">ICCV, 2025</div>
          <div class="publication-links">
            <a href="https://lyra-omni.github.io/">Project</a>
            <a href="https://arxiv.org/abs/2412.09501">arXiv</a> /
            <a href="https://www.youtube.com/watch?v=7kh-M0jmmtI">Video</a> /
            <a href="https://github.com/dvlab-research/Lyra" class="code-link" data-github-repo="dvlab-research/Lyra">Code</a><span class="github-stars" data-github-repo="dvlab-research/Lyra"></span> /
          </div>
        </div>
      </div>

      <!-- Mini-Gemini -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/minigemini-default.png" alt="Mini-Gemini" class="pub-img-default" />
          <img src="images/minigemini.png" alt="Mini-Gemini" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models</div>
          <div class="publication-authors">Yanwei Li*, <span class="author-name">Yuechen Zhang*</span>, Chengyao Wang*, Zhisheng Zhong, Yixin Chen, Ruihang Chu, Shaoteng Liu, Jiaya Jia</div>
          <div class="publication-venue">TPAMI, 2025</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2403.18814">arXiv</a> /
            <a href="https://mini-gemini.github.io/">Project</a> /
            <a href="https://github.com/dvlab-research/MiniGemini" class="code-link" data-github-repo="dvlab-research/MiniGemini">Code</a><span class="github-stars" data-github-repo="dvlab-research/MiniGemini"></span>
          </div>
        </div>
      </div>

      <!-- Prompt Highlighter -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/ph-default.png" alt="Prompt Highlighter" class="pub-img-default" />
          <img src="images/ph.png" alt="Prompt Highlighter" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">Prompt Highlighter: Interactive Control for Multi-Modal LLMs</div>
          <div class="publication-authors"><span class="author-name">Yuechen Zhang</span>, Shengju Qian, Bohao Peng, Shu Liu, Jiaya Jia</div>
          <div class="publication-venue">CVPR, 2024</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2312.04302">arXiv</a> /
            <a href="projects/PromptHighlighter/">Project</a> /
            <a href="https://github.com/dvlab-research/Prompt-Highlighter/" class="code-link" data-github-repo="dvlab-research/Prompt-Highlighter">Code</a><span class="github-stars" data-github-repo="dvlab-research/Prompt-Highlighter"></span>
          </div>
        </div>
      </div>

      <!-- RIVAL -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/rival-default.png" alt="RIVAL" class="pub-img-default" />
          <img src="images/rival.png" alt="RIVAL" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">Real-World Image Variation by Aligning Diffusion Inversion Chain</div>
          <div class="publication-authors"><span class="author-name">Yuechen Zhang</span>, Jinbo Xing, Eric Lo, Jiaya Jia</div>
          <div class="publication-venue">NeurIPS (Spotlight), 2023</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2305.18729">arXiv</a> /
            <a href="https://rival-diff.github.io/">Project</a> /
            <a href="https://github.com/julianjuaner/RIVAL/" class="code-link" data-github-repo="julianjuaner/RIVAL">Code</a><span class="github-stars" data-github-repo="julianjuaner/RIVAL"></span>
          </div>
        </div>
      </div>

      <!-- Ref-NPR -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/ref-npr-default.gif" alt="Ref-NPR" class="pub-img-default" />
          <img src="images/ref-npr.png" alt="Ref-NPR" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">Ref-NPR: Reference-Based Non-Photorealistic Radiance Fields</div>
          <div class="publication-authors"><span class="author-name">Yuechen Zhang</span>, Zexin He, Jinbo Xing, Xufeng Yao, Jiaya Jia</div>
          <div class="publication-venue">CVPR, 2023</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2212.02766">arXiv</a> /
            <a href="https://ref-npr.github.io">Project</a> /
            <a href="https://github.com/dvlab-research/Ref-NPR" class="code-link" data-github-repo="dvlab-research/Ref-NPR">Code</a><span class="github-stars" data-github-repo="dvlab-research/Ref-NPR"></span>
          </div>
        </div>
      </div>

      <!-- Video-P2P -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/videop2p.gif" alt="Video-P2P" class="pub-img-default" />
          <img src="images/videop2p.png" alt="Video-P2P" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">Video-P2P: Video Editing with Cross-attention Control</div>
          <div class="publication-authors">Shaoteng Liu, <span class="author-name">Yuechen Zhang</span>, Wenbo Li, Zhe Lin, Jiaya Jia</div>
          <div class="publication-venue">CVPR, 2024</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2303.04761">arXiv</a> /
            <a href="https://video-p2p.github.io/">Project</a> /
            <a href="https://github.com/ShaoTengLiu/Video-P2P" class="code-link" data-github-repo="ShaoTengLiu/Video-P2P">Code</a><span class="github-stars" data-github-repo="ShaoTengLiu/Video-P2P"></span>
          </div>
        </div>
      </div>

      <!-- DreamOmni -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/dreamomni-default.png" alt="DreamOmni" class="pub-img-default" />
          <img src="images/dreamomni.png" alt="DreamOmni" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">DreamOmni: Unified Image Generation and Editing</div>
          <div class="publication-authors">Bin Xia, <span class="author-name">Yuechen Zhang</span>, Jingyao Li, Chengyao Wang, Yitong Wang, Xinglong Wu, Bei Yu, Jiaya Jia</div>
          <div class="publication-venue">CVPR, 2025</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2406.02816">arXiv</a> /
            <a href="https://zj-binxia.github.io/DreamOmni-ProjectPage/">Project</a> /
            <a href="https://github.com/zj-binxia/DreamOmni" class="code-link" data-github-repo="zj-binxia/DreamOmni">Code</a><span class="github-stars" data-github-repo="zj-binxia/DreamOmni"></span>
          </div>
        </div>
      </div>

      <!-- DreamOmni2 -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/do2_default.png" alt="DreamOmni2" class="pub-img-default" />
          <img src="images/do2.png" alt="DreamOmni2" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">DreamOmni2: Multimodal Instruction-based Editing and Generation</div>
          <div class="publication-authors">Bin Xia, Bohao Peng, <span class="author-name">Yuechen Zhang</span>, Junjia Huang, Jiyang Liu, Jingyao Li, Haoru Tan, Sitong Wu, Chengyao Wang, Yitong Wang, Xinglong Wu, Bei Yu, Jiaya Jia</div>
          <div class="publication-venue">Preprint, 2025</div>
          <div class="publication-links">
            <a href="https://pbihao.github.io/projects/DreamOmni2/index.html">Project</a> /
            <a href="https://huggingface.co/spaces/wcy1122/DreamOmni2-Gen">Demo</a> /
            <a href="https://arxiv.org/abs/2510.06679">arXiv</a> /
            <a href="https://github.com/dvlab-research/DreamOmni2" class="code-link" data-github-repo="dvlab-research/DreamOmni2">Code</a><span class="github-stars" data-github-repo="dvlab-research/DreamOmni2"></span>
          </div>
        </div>
      </div>

      <!-- UniVA -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/univa-default.png" alt="UniVA" class="pub-img-default" />
          <img src="images/univa-default.png" alt="UniVA" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">UniVA: Universal Video Agent towards Open-Source Next-Generation Video Generalist</div>
          <div class="publication-authors">Zhengyang Liang, Daoan Zhang, Huichi Zhou, Rui Huang, Bobo Li, <span class="author-name">Yuechen Zhang</span>, Shengqiong Wu, Xiaohan Wang, Jiebo Luo, Lizi Liao, Hao Fei</div>
          <div class="publication-venue">Preprint, 2025</div>
          <div class="publication-links">
            <a href="https://univa.online/">Project</a> /
            <a href="https://arxiv.org/abs/2511.08521">arXiv</a> /
            <a href="https://github.com/univa-agent/univa" class="code-link" data-github-repo="univa-agent/univa">Code</a><span class="github-stars" data-github-repo="univa-agent/univa"></span>
          </div>
        </div>
      </div>

      <!-- ControlNeXt -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/controlnext-default.gif" alt="ControlNeXt" class="pub-img-default" />
          <img src="images/controlnext.png" alt="ControlNeXt" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">ControlNeXt: Powerful and Efficient Control for Image and Video Generation</div>
          <div class="publication-authors">Bohao Peng, Jian Wang, <span class="author-name">Yuechen Zhang</span>, Wenbo Li, Ming-Chang Yang, Jiaya Jia</div>
          <div class="publication-venue">Preprint, 2024</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2408.06070">arXiv</a> /
            <a href="https://pbihao.github.io/projects/controlnext/index.html">Project</a> /
            <a href="https://huggingface.co/spaces/Eugeoter/ControlNeXt">Demo</a> /
            <a href="https://github.com/dvlab-research/ControlNeXt" class="code-link" data-github-repo="dvlab-research/ControlNeXt">Code</a><span class="github-stars" data-github-repo="dvlab-research/ControlNeXt"></span>
          </div>
        </div>
      </div>

      <!-- R^2 -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/r2-default.png" alt="R^2" class="pub-img-default" />
          <img src="images/r2.png" alt="R^2" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">R<sup>2</sup>Former: Probing Region Relationship in Semantic Segmentation Transformers</div>
          <div class="publication-authors"><span class="author-name">Yuechen Zhang</span>, Tiancheng Shen*, Huaijia Lin, Lu Qi, Eric Lo, Jiaya Jia</div>
          <div class="publication-venue">Preprint, 2022</div>
        </div>
      </div>

      <!-- CRM -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/crm-default.png" alt="CRM" class="pub-img-default" />
          <img src="images/crm.png" alt="CRM" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">High Quality Segmentation for Ultra High-resolution Images</div>
          <div class="publication-authors">Tiancheng Shen, <span class="author-name">Yuechen Zhang</span>, Lu Qi, Jason Kuen, Xingyu Xie, Jianlong Wu, Zhe Lin, Jiaya Jia</div>
          <div class="publication-venue">CVPR, 2022</div>
          <div class="publication-links">
            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_High_Quality_Segmentation_for_Ultra_High-Resolution_Images_CVPR_2022_paper.pdf">Paper</a> /
            <a href="https://github.com/dvlab-research/Entity/tree/main/High-Quality-Segmention" class="code-link" data-github-repo="dvlab-research/Entity">Code</a><span class="github-stars" data-github-repo="dvlab-research/Entity"></span>
          </div>
        </div>
      </div>

      <!-- ResMaster -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/resmaster.png" alt="ResMaster" class="pub-img-default" />
          <img src="images/resmaster.png" alt="ResMaster" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">ResMaster: Mastering High-Resolution Image Generation via Structural and Fine-Grained Guidance</div>
          <div class="publication-authors">Shuwei Shi, Wenbo Li, <span class="author-name">Yuechen Zhang</span>, Jingwen He, Biao Gong, Yinqiang Zheng</div>
          <div class="publication-venue">AAAI, 2025</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2406.16476">arXiv</a>
          </div>
        </div>
      </div>

      <!-- Make-Your-Video -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/make-your-video.gif" alt="Make-Your-Video" class="pub-img-default" />
          <img src="images/make-your-video.gif" alt="Make-Your-Video" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">Make-Your-Video: Customized Video Generation Using Textual and Structural Guidance</div>
          <div class="publication-authors">Jinbo Xing, Menghan Xia, Yuxin Liu, <span class="author-name">Yuechen Zhang</span>, Yong Zhang, Yingqing He, Hanyuan Liu, Haoxin Chen, Xiaodong Cun, Xintao Wang, Ying Shan, Tien-Tsin Wong</div>
          <div class="publication-venue">TVCG, 2025</div>
          <div class="publication-links">
            <a href="https://www.computer.org/csdl/journal/tg/2025/02/10436391/1UwVf2MBnby">Paper</a> /
            <a href="https://arxiv.org/abs/2306.00943">arXiv</a> /
            <a href="https://doubiiu.github.io/projects/Make-Your-Video/">Project</a> /
            <a href="https://github.com/AILab-CVC/Make-Your-Video" class="code-link" data-github-repo="AILab-CVC/Make-Your-Video">Code</a><span class="github-stars" data-github-repo="AILab-CVC/Make-Your-Video"></span>
          </div>
          <div class="publication-desc">Customized video generation using textual and structural guidance.</div>
        </div>
      </div>


      <!-- CodeTalker -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/codetalker.png" alt="CodeTalker" class="pub-img-default" />
          <video class="pub-img-hover" muted autoplay loop>
            <source src="images/codetalker_video.mp4" type="video/mp4">
          </video>
        </div>
        <div class="publication-content">
          <div class="publication-title">CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior</div>
          <div class="publication-authors">Jinbo Xing, Menghan Xia, <span class="author-name">Yuechen Zhang</span>, Xiaodong Cun, Jue Wang, Tien-Tsin Wong</div>
          <div class="publication-venue">CVPR, 2023</div>
          <div class="publication-links">
            <a href="https://arxiv.org/abs/2301.02379">arXiv</a> /
            <a href="https://doubiiu.github.io/projects/codetalker/">Project</a> /
            <a href="https://github.com/Doubiiu/CodeTalker" class="code-link" data-github-repo="Doubiiu/CodeTalker">Code</a><span class="github-stars" data-github-repo="Doubiiu/CodeTalker"></span>
          </div>
        </div>
      </div>

      <!-- KDiffusion -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/kdiffusion.png" alt="KDiffusion" class="pub-img-default" />
          <img src="images/kdiffusion.png" alt="KDiffusion" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">Progressively Knowledge Distillation via Re-parameterizing Diffusion Reverse Process</div>
          <div class="publication-authors">Xufeng Yao, Fanbin Lu, <span class="author-name">Yuechen Zhang</span>, Xinyun Zhang, Wenqian Zhao, Bei Yu</div>
          <div class="publication-venue">AAAI, 2024</div>
          <div class="publication-links">
            <a href="https://www.cse.cuhk.edu.hk/~byu/papers/C199-AAAI2024-KDiffusion.pdf">Paper</a>
          </div>
        </div>
      </div>

      <!-- PCL -->
      <div class="publication-item">
        <div class="publication-image">
          <img src="images/pcl-default.png" alt="PCL" class="pub-img-default" />
          <img src="images/pcl.png" alt="PCL" class="pub-img-hover" />
        </div>
        <div class="publication-content">
          <div class="publication-title">PCL: Proxy-based Contrastive Learning for Domain Generalization</div>
          <div class="publication-authors">Xufeng Yao, Yang Bai, Xinyun Zhang, <span class="author-name">Yuechen Zhang</span>, Qi Sun, Ran Chen, Ruiyu Li, Bei Yu</div>
          <div class="publication-venue">CVPR, 2022</div>
          <div class="publication-links">
            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yao_PCL_Proxy-Based_Contrastive_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf">Paper</a> /
            <a href="https://github.com/yaoxufeng/PCL-Proxy-based-Contrastive-Learning-for-Domain-Generalization" class="code-link" data-github-repo="yaoxufeng/PCL-Proxy-based-Contrastive-Learning-for-Domain-Generalization">Code</a><span class="github-stars" data-github-repo="yaoxufeng/PCL-Proxy-based-Contrastive-Learning-for-Domain-Generalization"></span>
          </div>
        </div>
      </div>

      <!-- Flow-Aware Video-to-Video Synthesis -->
      <div class="publication-item">
        <div class="publication-image">
          <video class="pub-img-hover" muted autoplay loop>
            <source src="images/FVI.mp4" type="video/mp4">
          </video>
          <video class="pub-img-default" muted autoplay loop>
            <source src="images/FVI.mp4" type="video/mp4">
          </video>
        </div>
        <div class="publication-content">
          <div class="publication-title">Flow-aware Synthesis: A Generic Motion Model for Video Frame Interpolation</div>
          <div class="publication-authors">Jinbo Xing*, Wenbo Hu*, <span class="author-name">Yuechen Zhang</span>, Tien-Tsin Wong</div>
          <div class="publication-venue">Computational Visual Media (CVM), 2021</div>
          <div class="publication-links">
            <a href="https://link.springer.com/article/10.1007/s41095-021-0208-x">Paper</a>
          </div>
        </div>
      </div>

    </div>
  </section>
    <!-- ÊïôËÇ≤‰∏éÂ∑•‰ΩúÁªèÂéÜ Section -->
    <section id="education" class="education-section">
      <h2 class="section-title">Education & Work Experience</h2>
      <div class="education-list">
        <div class="edu-block">
          <div class="edu-header">
            <span class="edu-school">The Chinese University of Hong Kong</span>
            <span class="edu-location">Hong Kong</span>
          </div>
          <div class="edu-detail">
            <span class="edu-degree">Doctor of Philosophy, Computer Science.</span>
            <span class="edu-time">Aug 2021 - Dec 2025 (expected)</span>
          </div>
          <div class="edu-desc">Supervisor: Prof. Jia Jiaya, Prof. Eric Lo</div>
          <div class="edu-detail">
            <span class="edu-degree">Bachelor of Computer Science</span>
            <span class="edu-time">Sep 2016 - Jul 2021</span>
          </div>
          <div class="edu-desc">First Class Honour, ELITE Stream</div>
        </div>
        <div class="edu-block">
          <div class="edu-header">
            <span class="edu-school">Nanyang Technological University</span>
            <span class="edu-location">Singapore</span>
          </div>
          <div class="edu-detail">
            <span class="edu-degree">[Exchange] GEM Trailblazer Exchange Program</span>
            <span class="edu-time">Jan 2019 - May 2019</span>
          </div>
        </div>
        <div class="edu-block">
          <div class="edu-header">
            <span class="edu-school">Tsinghua University</span>
            <span class="edu-location">Beijing, China</span>
          </div>
          <div class="edu-detail">
            <span class="edu-degree">[Exchange] Yao Class Summer Program</span>
            <span class="edu-time">Jul 2019 - Aug 2019</span>
          </div>
        </div>
      </div>
      <div class="work-list">
        <div class="work-block">
          <div class="work-header">
            <span class="work-company">Kling, Kuaishou</span>
            <span class="work-location">Shenzhen, China</span>
          </div>
          <div class="work-detail">
            <span class="work-title">Research Internship</span>
            <span class="work-time">Feb 2025 - June 2025</span>
          </div>
          <div class="work-desc">Research on efficient video generation.</div>
        </div>
        <div class="work-block">
          <div class="work-header">
            <span class="work-company">LightSpeed, Tencent</span>
            <span class="work-location">Hong Kong</span>
          </div>
          <div class="work-detail">
            <span class="work-title">Research Internship</span>
            <span class="work-time">Feb 2024 - Jul 2024</span>
          </div>
          <div class="work-desc">Research on interactive video generation and customization.</div>
        </div>
        <div class="work-block">
          <div class="work-header">
            <span class="work-company">SmartMore</span>
            <span class="work-location">Hong Kong</span>
          </div>
          <div class="work-detail">
            <span class="work-title">Work Study Internship</span>
            <span class="work-time">Jan 2020 - Jul 2025</span>
          </div>
          <div class="work-desc">Research on image segmentation on real-world industry projects, including defect detection and chip circuit high-precision instance segmentation. Developing an algorithm for 2D Datamatrix code recognition and decoding.</div>
        </div>
      </div>
    </section>

    <!-- AWARDS & COMMUNITY CONTRIBUTIONS Section -->
    <section id="awards" class="awards-section">
      <h2 class="section-title">Awards & Community Contributions</h2>
      <ul class="awards-list">
        <li>CUHK ELITE Stream Scholarship, 2016-2017, 2017-2018</li>
        <li>CUHK CSE Academic Outstanding Award, 2017-2018, 2018-2019, 2019-2020</li>
        <li>CUHK Faculty of Engineering, Dean's List, 2016-2017, 2017-2018</li>
        <li>CWChu College Exchange Scholarship, 2018-2019</li>
        <li>CWChu College Scholarships for Academic Excellence, 2017-2018, 2018-2019, 2019-2020</li>
        <li>Teaching Assistant: CSCI3280 Intro. to Multimedia, ESTR4999 Final Year Project, CSCI3250/3251: Computer and Society.</li>
        <li>Conference Reviewer: CVPR, NeurIPS, ICCV, ECCV, ICLR, AAAI</li>
        <li>Top Reviewer: NeurIPS 2025</li>
      </ul>
    </section>

    <script>
      const headerContainer = document.querySelector('.header-container');
      if (headerContainer) {
        const headerMaskLayer = headerContainer.querySelector('.header-mask-layer');
        const headerPatterns = Array.from(headerContainer.querySelectorAll('.header-pattern'));
        const motionToggle = headerContainer.querySelector('.header-motion-toggle');
        let targetX = 50;
        let targetY = 50;
        let currentX = 50;
        let currentY = 50;
        let trailX = 50;
        let trailY = 50;
        let targetPatternX = 0;
        let targetPatternY = 0;
        let currentPatternX = 0;
        let currentPatternY = 0;
        let rafId = null;
        let isDragging = false;
        let maskRadius = 500;
        let motionEnabled = true;
        let isCircleAnimating = false;

        const isPortrait = () => window.innerHeight > window.innerWidth;

        const updateMaskRadius = () => {
          const raw = getComputedStyle(headerContainer).getPropertyValue('--spot-size');
          const parsed = Number.parseFloat(raw);
          maskRadius = Number.isFinite(parsed) ? parsed : 500;
        };

        const buildCapsulePath = (x1, y1, x2, y2, r) => {
          const dx = x2 - x1;
          const dy = y2 - y1;
          const dist = Math.hypot(dx, dy);
          if (dist < 1) {
            const startX = x1 + r;
            return `M ${startX} ${y1} A ${r} ${r} 0 1 0 ${x1 - r} ${y1} A ${r} ${r} 0 1 0 ${startX} ${y1} Z`;
          }
          const angle = Math.atan2(dy, dx);
          const offsetX = Math.sin(angle) * r;
          const offsetY = -Math.cos(angle) * r;
          const p1aX = x1 + offsetX;
          const p1aY = y1 + offsetY;
          const p1bX = x1 - offsetX;
          const p1bY = y1 - offsetY;
          const p2aX = x2 + offsetX;
          const p2aY = y2 + offsetY;
          const p2bX = x2 - offsetX;
          const p2bY = y2 - offsetY;
          return [
            `M ${p1aX} ${p1aY}`,
            `L ${p2aX} ${p2aY}`,
            `A ${r} ${r} 0 0 1 ${p2bX} ${p2bY}`,
            `L ${p1bX} ${p1bY}`,
            `A ${r} ${r} 0 0 1 ${p1aX} ${p1aY}`,
            'Z'
          ].join(' ');
        };

        const buildPattern = (patternElement) => {
          if (!patternElement) {
            return;
          }
          const rows = 16;
          const cols = 30;
          const text = 'YUECHEN';
          const fragment = document.createDocumentFragment();
          for (let i = 0; i < rows; i += 1) {
            const row = document.createElement('div');
            row.className = 'header-pattern-row';
            for (let j = 0; j < cols; j += 1) {
              const span = document.createElement('span');
              span.className = 'header-pattern-text';
              span.textContent = text;
              row.appendChild(span);
            }
            fragment.appendChild(row);
          }
          patternElement.innerHTML = '';
          patternElement.appendChild(fragment);
        };

        const animateSpotlight = () => {
          if (!motionEnabled) {
            rafId = null;
            return;
          }
          currentX += (targetX - currentX) * 0.18;
          currentY += (targetY - currentY) * 0.18;
          trailX += (currentX - trailX) * 0.08;
          trailY += (currentY - trailY) * 0.08;
          currentPatternX += (targetPatternX - currentPatternX) * 0.12;
          currentPatternY += (targetPatternY - currentPatternY) * 0.12;
          const bounds = headerContainer.getBoundingClientRect();
          const currentPxX = (currentX / 100) * bounds.width;
          const currentPxY = (currentY / 100) * bounds.height;
          const trailPxX = (trailX / 100) * bounds.width;
          const trailPxY = (trailY / 100) * bounds.height;
          if (headerMaskLayer) {
            const path = buildCapsulePath(currentPxX, currentPxY, trailPxX, trailPxY, maskRadius);
            headerMaskLayer.style.clipPath = `path('${path}')`;
            headerMaskLayer.style.webkitClipPath = `path('${path}')`;
          }
          headerPatterns.forEach((patternElement) => {
            patternElement.style.setProperty('--pattern-x', `${currentPatternX}px`);
            patternElement.style.setProperty('--pattern-y', `${currentPatternY}px`);
          });
          rafId = requestAnimationFrame(animateSpotlight);
        };

        const updateTarget = (event) => {
          if (!motionEnabled) {
            return;
          }
          const bounds = headerContainer.getBoundingClientRect();
          targetX = ((event.clientX - bounds.left) / bounds.width) * 100;
          targetY = ((event.clientY - bounds.top) / bounds.height) * 100;
          if (!isDragging) {
            const relativeX = (event.clientX - bounds.left - bounds.width / 2) / bounds.width;
            const relativeY = (event.clientY - bounds.top - bounds.height / 2) / bounds.height;
            targetPatternX = relativeX * 80;
            targetPatternY = relativeY * 60;
          } else {
            targetPatternX += event.movementX;
            targetPatternY += event.movementY;
          }
          headerContainer.classList.add('header-spotlight-active');
          if (!rafId) {
            rafId = requestAnimationFrame(animateSpotlight);
          }
        };

        const stopSpotlight = () => {
          headerContainer.classList.remove('header-spotlight-active');
          if (rafId) {
            cancelAnimationFrame(rafId);
            rafId = null;
          }
        };

        const setMotionEnabled = (enabled, centerPercent) => {
          if (isCircleAnimating) return;
          motionEnabled = enabled;
          if (enabled) {
            headerContainer.classList.remove('header-motion-off');
          }
          if (motionToggle) {
            motionToggle.setAttribute('aria-pressed', String(enabled));
            motionToggle.textContent = enabled ? 'Motion On' : 'Motion Off';
          }
          const bounds = headerContainer.getBoundingClientRect();
          // Close: always use current spotlight position so circle shrinks in place (no teleport)
          const closeX = currentX;
          const closeY = currentY;
          // Open: use click position; will sync spotlight state to this position when animation ends
          const openX = centerPercent ? centerPercent.x : 50;
          const openY = centerPercent ? centerPercent.y : 50;
          if (!enabled) {
            if (headerMaskLayer) {
              isCircleAnimating = true;
              headerMaskLayer.classList.add('header-mask-layer--circle');
              headerMaskLayer.style.opacity = '1';
              headerMaskLayer.style.clipPath = `circle(${maskRadius}px at ${closeX}% ${closeY}%)`;
              headerMaskLayer.style.webkitClipPath = headerMaskLayer.style.clipPath;
              stopSpotlight();
              requestAnimationFrame(() => {
                requestAnimationFrame(() => {
                  headerMaskLayer.style.clipPath = `circle(0 at ${closeX}% ${closeY}%)`;
                  headerMaskLayer.style.webkitClipPath = headerMaskLayer.style.clipPath;
                  const onCloseEnd = () => {
                    headerMaskLayer.removeEventListener('transitionend', onCloseEnd);
                    headerMaskLayer.classList.add('header-mask-layer--closing');
                    headerContainer.classList.add('header-motion-off');
                    headerMaskLayer.style.opacity = '0';
                    requestAnimationFrame(() => {
                      headerMaskLayer.classList.remove('header-mask-layer--circle', 'header-mask-layer--closing');
                      headerMaskLayer.style.opacity = '';
                      isCircleAnimating = false;
                    });
                  };
                  headerMaskLayer.addEventListener('transitionend', onCloseEnd);
                });
              });
            } else {
              stopSpotlight();
              headerContainer.classList.add('header-motion-off');
            }
          } else {
            if (headerMaskLayer) {
              isCircleAnimating = true;
              headerMaskLayer.classList.add('header-mask-layer--circle');
              headerMaskLayer.style.opacity = '1';
              headerMaskLayer.style.clipPath = `circle(0 at ${openX}% ${openY}%)`;
              headerMaskLayer.style.webkitClipPath = headerMaskLayer.style.clipPath;
              requestAnimationFrame(() => {
                headerMaskLayer.style.clipPath = `circle(${maskRadius}px at ${openX}% ${openY}%)`;
                headerMaskLayer.style.webkitClipPath = headerMaskLayer.style.clipPath;
                const onOpenEnd = () => {
                  headerMaskLayer.removeEventListener('transitionend', onOpenEnd);
                  headerMaskLayer.classList.remove('header-mask-layer--circle');
                  headerMaskLayer.style.opacity = '';
                  const cx = (openX / 100) * bounds.width;
                  const cy = (openY / 100) * bounds.height;
                  headerMaskLayer.style.clipPath = `path('${buildCapsulePath(cx, cy, cx, cy, maskRadius)}')`;
                  headerMaskLayer.style.webkitClipPath = headerMaskLayer.style.clipPath;
                  // Sync spotlight state to circle center so no jump when handing off to mouse follow
                  currentX = openX;
                  currentY = openY;
                  targetX = openX;
                  targetY = openY;
                  trailX = openX;
                  trailY = openY;
                  headerContainer.classList.add('header-spotlight-active');
                  if (!rafId) rafId = requestAnimationFrame(animateSpotlight);
                  isCircleAnimating = false;
                };
                headerMaskLayer.addEventListener('transitionend', onOpenEnd);
              });
            }
          }
        };

        const startDrag = () => {
          isDragging = true;
          headerContainer.classList.add('header-pattern-dragging');
        };

        const endDrag = () => {
          isDragging = false;
          headerContainer.classList.remove('header-pattern-dragging');
        };

        updateMaskRadius();
        headerPatterns.forEach((patternElement) => buildPattern(patternElement));
        headerContainer.addEventListener('mousemove', updateTarget);
        headerContainer.addEventListener('mouseenter', updateTarget);
        headerContainer.addEventListener('mouseleave', stopSpotlight);
        headerContainer.addEventListener('mousedown', startDrag);
        window.addEventListener('mouseup', endDrag);
        window.addEventListener('resize', updateMaskRadius);
        if (motionToggle) {
          motionToggle.addEventListener('click', (e) => {
            const bounds = headerContainer.getBoundingClientRect();
            const center = {
              x: ((e.clientX - bounds.left) / bounds.width) * 100,
              y: ((e.clientY - bounds.top) / bounds.height) * 100
            };
            setMotionEnabled(!motionEnabled, center);
          });
        }
        headerContainer.addEventListener('dblclick', (e) => {
          if (e.target.closest('.header-motion-controls')) return;
          const bounds = headerContainer.getBoundingClientRect();
          const center = {
            x: ((e.clientX - bounds.left) / bounds.width) * 100,
            y: ((e.clientY - bounds.top) / bounds.height) * 100
          };
          setMotionEnabled(!motionEnabled, center);
        });
        if (isPortrait()) {
          setMotionEnabled(false);
        }
      }

      // Ê†ºÂºèÂåñstarÊï∞ÈáèÔºà‰æãÂ¶ÇÔºö1234 -> "1.2k"Ôºâ
      function formatStars(count) {
        if (count >= 1000) {
          return (count / 1000).toFixed(1) + 'k';
        }
        return count.toString();
      }

      // Ëé∑ÂèñGitHub starÊï∞Èáè
      async function fetchGitHubStars(repo) {
        try {
          const response = await fetch(`https://api.github.com/repos/${repo}`, {
            headers: {
              'Accept': 'application/vnd.github.v3+json'
            }
          });
          if (response.ok) {
            const data = await response.json();
            return data.stargazers_count;
          } else if (response.status === 404) {
            console.warn(`Repository ${repo} not found`);
          } else if (response.status === 403) {
            console.warn(`Rate limit exceeded for ${repo}`);
          } else {
            console.warn(`Failed to fetch ${repo}: ${response.status}`);
          }
        } catch (error) {
          console.error(`Error fetching stars for ${repo}:`, error);
        }
        return null;
      }

      // Êõ¥Êñ∞ÊâÄÊúâGitHub starÊòæÁ§∫
      async function updateAllStars() {
        const starElements = document.querySelectorAll('.github-stars[data-github-repo]');
        if (starElements.length === 0) {
          console.log('No star elements found');
          return;
        }

        console.log(`Found ${starElements.length} star elements`);
        const repos = new Set();
        
        // Êî∂ÈõÜÊâÄÊúâÂîØ‰∏ÄÁöÑ‰ªìÂ∫ì
        starElements.forEach(el => {
          const repo = el.getAttribute('data-github-repo');
          if (repo) {
            repos.add(repo);
            console.log(`Found repo: ${repo}`);
          }
        });

        console.log(`Fetching stars for ${repos.size} unique repos`);
        
        // ÊâπÈáèËé∑ÂèñstarÊï∞ÈáèÔºàÊ∑ªÂä†Âª∂Ëøü‰ª•ÈÅøÂÖçÈÄüÁéáÈôêÂà∂Ôºâ
        const results = [];
        for (const repo of repos) {
          const stars = await fetchGitHubStars(repo);
          results.push({ repo, stars });
          console.log(`Repo ${repo}: ${stars !== null ? stars : 'failed'} stars`);
          // Ê∑ªÂä†Â∞èÂª∂Ëøü‰ª•ÈÅøÂÖçËß¶ÂèëGitHub APIÈÄüÁéáÈôêÂà∂
          await new Promise(resolve => setTimeout(resolve, 200));
        }
        
        // Êõ¥Êñ∞ÊâÄÊúâÂØπÂ∫îÁöÑÂÖÉÁ¥†
        let updatedCount = 0;
        starElements.forEach(el => {
          const repo = el.getAttribute('data-github-repo');
          const result = results.find(r => r.repo === repo);
          if (result && result.stars !== null && result.stars !== undefined) {
            el.textContent = ` ‚≠ê ${formatStars(result.stars)}`;
            el.style.display = 'inline';
            updatedCount++;
          } else {
            el.style.display = 'none';
          }
        });
        
        console.log(`Updated ${updatedCount} star displays`);
      }

      // È°µÈù¢Âä†ËΩΩÂÆåÊàêÂêéËé∑ÂèñstarÊï∞Èáè
      if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', updateAllStars);
      } else {
        // Âª∂Ëøü‰∏ÄÁÇπÊâßË°åÔºåÁ°Æ‰øùDOMÂÆåÂÖ®Âä†ËΩΩ
        setTimeout(updateAllStars, 100);
      }
    </script>
</body>
</html>
